{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple Autoencoder - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, we will try to build a simple autoencoder using Keras. We will work with the fashion-MNIST dataset to work out a problem of image compression and reconstruction. With a simple AE, the results may not be highly impressive, but the key takeaway from this lab is to see how the encoding/decoding functions are implemented neural nets and are differentiable with respect to the distance function. The differentiable part enables optimizing the parameters of the encoding/decoding functions to minimize the reconstruction loss.\n",
    "\n",
    "Note: Refer to [Keras dcumentation](https://keras.io/) for details on methods used in this lab. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Build a simple autoencoder in Keras\n",
    "- Create the encoder and decoder functions as fully connected layers of a feed forward styled neural network. \n",
    "- Train an autoencoder with selected loss function and optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import all the necessary libraries required for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow and keras if you haven't done so already\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fashion-MNIST dataset\n",
    "\n",
    "We have already seen the popular MNIST dataset in our previous lessons. Let's load the very similar [\"fashion-mnist\" dataset](https://github.com/zalandoresearch/fashion-mnist). \n",
    "\n",
    "*\"Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\"* \n",
    "\n",
    "This dataset comes packaged with keras and can be loaded using `fashion_mnist.load_data()`. More details on keras datasets can be seen on [keras documentation](https://keras.io/datasets/). Below is a quick sample of images that you may find in this dataset.\n",
    "\n",
    "<img src=\"dataset.png\" width=700>\n",
    "\n",
    "Perform following tasks:\n",
    "- Load the Fashion-mnist feature set into test and training datasets (ignore labels/targets for now)\n",
    "- Normalize the values of train and test datasets between 0 and 1\n",
    "- Check the shape of both datasets created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / float(x_train.max())\n",
    "x_test = x_test.astype('float32') / float(x_train.max())\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that we have 3D arrays of train and test datasets containg 60K and 10K images of size 28x28 pixels. To work with the images as vectors, let’s reshape the 3D arrays as 2D matrices. \n",
    "\n",
    "- Reshape the 28 x 28 images into vectors of length 784 for both train and test set\n",
    "- Print the shape of new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Simple AutoEncoder\n",
    "\n",
    "With our pre-processed data, we can start building a simple autoencoder with its The encoder and decoder functions are each __fully-connected__ neural layers. The encoder function will use a __ReLU__ (Rectified Linear Unit) activation function, while the decoder function uses a __sigmoid__ activation function.\n",
    "\n",
    "[Here is a good reference on non-linear functions](https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f). \n",
    "\n",
    "> The encoder layer encodes the input image as a compressed, latent representation with reduced dimensionality. The decoder layer decodes the encoded image back to the original dimension. \n",
    "\n",
    "Here we will create the compressed representation with 32 dimensions with a __compression factor__  784 / 32 = 24.5\n",
    "\n",
    "Let's build our Model . Perform following tasks.\n",
    "\n",
    "- Define encoding dimensions (32) and calculate/print the compression factor\n",
    "- Create a `Sequential()` autoencoder model in Keras\n",
    "\n",
    "- Create a fully connected  __encoder layer__  to reduce the dimension from the original 784-dimensional vector to encoded 32-dimensional vector. Use the `relu` activation function\n",
    "\n",
    "- Create a fully connected __decoder layer__ to restore the dimension from the encoded 32-dimensional representation back to the original 784-dimensional vector.Use `sigmoid` activation function\n",
    "\n",
    "- Print he model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "compression_factor = float(x_train.shape[1] ) / 32\n",
    "print(compression_factor)\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(32, input_shape=(x_train.shape[1] ,), activation='relu'))\n",
    "autoencoder.add(Dense(x_train.shape[1] , activation='sigmoid'))\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Encoder\n",
    "Let's try to examine how a compressed representation compares to the original image. We can extract the encoder model from the first layer of the autoencoder model created above. \n",
    "\n",
    "- Extract the first layer of autoencoder to create a new `encoder` model in Keras\n",
    "- Show the summary of encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(input_dim,))\n",
    "encoder_layer = autoencoder.layers[0]\n",
    "encoder = Model(input_img, encoder_layer(input_img))\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks about right. We are now ready to train our autoencoder model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model \n",
    "\n",
    "In order to train the model, We need to perform following tasks: \n",
    "- Compile the autoencoder model with `adam` optimization with `binary_crossentropy` loss (The purpose of the loss function is to reconstruct an image similar to the input image). \n",
    "- Fit the model with training dataset for both input and output (this implies image reconstruction)\n",
    "- Iterate on the training data in batches of 256 in 20 epochs. Set `shuffle` to True for shuffling the batches.\n",
    "- Use the test data for validation \n",
    "\n",
    "(Try increasing number of epochs and observe the effect on learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.4144 - val_loss: -780.7460\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3299 - val_loss: -884.0864\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3115 - val_loss: -994.0015\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3020 - val_loss: -1060.7044\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2962 - val_loss: -1095.1344\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2925 - val_loss: -1121.1864\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2901 - val_loss: -1131.6861\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2884 - val_loss: -1137.9596\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2873 - val_loss: -1139.2266\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2864 - val_loss: -1142.0568\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2858 - val_loss: -1142.3259\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2853 - val_loss: -1144.0299\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2849 - val_loss: -1144.9266\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2846 - val_loss: -1144.9896\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.2843 - val_loss: -1145.4312\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2840 - val_loss: -1146.5099\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2835 - val_loss: -1146.2113\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2832 - val_loss: -1146.0113\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2831 - val_loss: -1145.7829\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2829 - val_loss: -1146.1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c51feff60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=20, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, We’ve successfully trained our autoencoder. Our  autoencoder model can now compress a Fashion MNIST image down to 32 floating-point digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The Results\n",
    "\n",
    "To visually inspect the quality of compressed images, let's pick up a few images randomly and see how their  reconstruction looks. \n",
    "\n",
    "- Select 10 images randomly from the test set\n",
    "- Uee the `encoder` model to predict encoded representation (the code) for chosen images\n",
    "- Use the `autoencoder` model to get the reconstructed images\n",
    "- For each image, show the actual image, the compressed representation and the reconstruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 10\n",
    "np.random.seed(50)\n",
    "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_test[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(8, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
    "    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, as expected, the reconstructed images are quite lossy due to the huge reduction in dimensionality. We can see the shapes of these objects clearly, but the loss in image quality has taken away a lot of distinguishing features. So the compression is not highly impressive, but it works , and proves the point. We can improve the peroformance of such AEs using deeper networks as we shall see in our next lab. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lab, we built a simple autoencoder using the fashion-MNIST dataset for a problem of image compression. We looked into creating the encoder and decoder layers in Keras and Training the model. We also visually inspected the results of this compression. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
